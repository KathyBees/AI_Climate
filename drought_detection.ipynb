{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ldOn_BV2GwKP",
    "outputId": "865ec8f2-4e19-4602-a406-b49e5c267e75",
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# if necessary, install NeuralGCM and dependencies\n",
    "!pip install -q -U neuralgcm dinosaur-dycore gcsfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_web7Ad1gunN"
   },
   "source": [
    "# Forecasting quick start\n",
    "\n",
    "This notebook uses ERA5 data and pretrained NeuralGCM model to make a weather forecast.\n",
    "\n",
    "The forecast is made in 3 steps:\n",
    "1. Slice of ERA5 data is regridded to model resolution\n",
    "2. NeuralGCM model state is initialized and rolled out\n",
    "3. Predictions and reference trajectory are combined for visualization\n",
    "\n",
    "By default the notebook uses intermediate deterministic NeuralGCM 1.4° model. Other available checkpoints include deterministic 0.7°, 2.8° and stochastic 1.4° NeuralGCM variations.\n",
    "\n",
    "```{tip}\n",
    "You can run this notebook yourself in [Google Colab](https://colab.research.google.com/github/google-research/neuralgcm/blob/main/docs/inference_demo.ipynb). We recommend using a GPU or TPU runtime due to high memory and compute requirements.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wTapB9c0AWMJ"
   },
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "import jax\n",
    "import numpy as np\n",
    "import pickle\n",
    "import xarray\n",
    "\n",
    "from dinosaur import horizontal_interpolation\n",
    "from dinosaur import spherical_harmonic\n",
    "from dinosaur import xarray_utils\n",
    "import neuralgcm\n",
    "\n",
    "gcs = gcsfs.GCSFileSystem(token='anon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the SST pattern that was send to us https://esgf-ui.ceda.ac.uk/cog/search/cmip6-ceda/ \n",
    "How to: \\\n",
    "tos in die Suchleiste\n",
    "<span style=\"color:red\">~~Download erledigt~~</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarai-pc-02/miniconda3/lib/python3.12/pty.py:95: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xarray in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (2024.10.0)\n",
      "Requirement already satisfied: netCDF4 in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: packaging>=23.1 in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (from xarray) (24.1)\n",
      "Requirement already satisfied: pandas>=2.1 in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (from xarray) (2.2.3)\n",
      "Requirement already satisfied: cftime in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (from netCDF4) (1.6.4.post1)\n",
      "Requirement already satisfied: certifi in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (from netCDF4) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (from pandas>=2.1->xarray) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (from pandas>=2.1->xarray) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (from pandas>=2.1->xarray) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/sarai-pc-02/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.1->xarray) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install xarray netCDF4 numpy\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "ersst_path = \"./data/tos_Omon_GISS-E2-1-G_historical_r1i1p5f1_gn_200101-201412.nc\"\n",
    "ersst_data = xr.open_dataset(ersst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the data to be similar to NeuralGCM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5uFP46Obo80"
   },
   "source": [
    "## Load a pre-trained NeuralGCM model\n",
    "\n",
    "```{caution}\n",
    "Trained model weights are licensed for non-commercial use, under the Creative Commons [Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/) license (CC BY-NC-SA 4.0).\n",
    "```\n",
    "\n",
    "Pre-trained model checkpoints from the NeuralGCM paper are [available for download](https://console.cloud.google.com/storage/browser/gresearch/neuralgcm/04_30_2024) on Google Cloud Storage:\n",
    "\n",
    "- Deterministic models:\n",
    "    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_deterministic_0_7_deg.pkl`\n",
    "    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_deterministic_1_4_deg.pkl`\n",
    "    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_deterministic_2_8_deg.pkl`\n",
    "- Stochastic models:\n",
    "    - `gs://gresearch/neuralgcm/04_30_2024/neural_gcm_dynamic_forcing_stochastic_1_4_deg.pkl`\n",
    "\n",
    "<span style=\"color:green\">NEW</span> \n",
    "## Need to train it on our own using the inputs from era5\n",
    "\n",
    "Checklist: \\\n",
    "~~Find out all variables~~ \\\n",
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "drought_variables = [\n",
    "    \"precipitation\",      # To track precipitation deficits\n",
    "    \"evaporation\",        # Water loss through evaporation\n",
    "    \"soil_moisture\",      # Soil water content for agricultural impacts\n",
    "    \"temperature\",        # High temperatures linked to drought\n",
    "    \"specific_humidity\",  # Tracks atmospheric moisture\n",
    "    \"surface_pressure\",   # Indicator of regional pressure systems\n",
    "    \"sea_surface_temp\",   # SST anomalies linked to teleconnections\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uQnv1GWKD1iP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79947/3277558506.py:4: DeprecationWarning: Pickled array contains an aval with a named_shape attribute. This is deprecated and the code path supporting such avals will be removed. Please re-pickle the array.\n",
      "  ckpt = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'neural_gcm_dynamic_forcing_deterministic_1_4_deg.pkl'  #@param ['neural_gcm_dynamic_forcing_deterministic_0_7_deg.pkl', 'neural_gcm_dynamic_forcing_deterministic_1_4_deg.pkl', 'neural_gcm_dynamic_forcing_deterministic_2_8_deg.pkl', 'neural_gcm_dynamic_forcing_stochastic_1_4_deg.pkl'] {type: \"string\"}\n",
    "\n",
    "with gcs.open(f'gs://gresearch/neuralgcm/04_30_2024/{model_name}', 'rb') as f:\n",
    "  ckpt = pickle.load(f)\n",
    "\n",
    "model = neuralgcm.PressureLevelModel.from_checkpoint(ckpt)\n",
    "\n",
    "##\n",
    "# TODO: Train on our own, Decide on training and testing data and do the 30 year roll out\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpEb_avqbo80"
   },
   "source": [
    "## Load ERA5 data from GCP/Zarr\n",
    "\n",
    "See {doc}`datasets` for details. Leave this part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66ZyTazL6GF7"
   },
   "source": [
    "Select out a few days of data:\n",
    "\n",
    "## Need to change start time and end time\n",
    "\n",
    "Checklist: \\\n",
    "~~Select spain as a region~~ \\\n",
    "<span style=\"color:red\">Decide on start and end time</span> \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_path = 'gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3'\n",
    "full_era5 = xarray.open_zarr(gcs.get_mapper(era5_path), chunks=None)\n",
    "\n",
    "start_date = '2020-02-14'\n",
    "end_date = '2020-02-18'\n",
    "data_inner_steps = 24  # process every 24th hour\n",
    "\n",
    "# Define the latitude and longitude bounds for Spain\n",
    "# Die Werte müssen eigentlich größer sein, da im Mittelmeer auch Abläufe sind, die das beeinflussen. Für die Fläche \n",
    "\n",
    "lat_bounds = slice(36, 44)  # Latitude range for Spain mainland\n",
    "lon_bounds = slice(-10, 4)  # Longitude range for Spain mainland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">NEW</span>Subset the data before adding it to era5 input for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Subset the data\n",
    "sst_subset = ersst_data['tos'].sel(time=slice(start_date, end_date),\n",
    "                                   lat=lat_bounds,\n",
    "                                   lon=lon_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">NEW</span> Compute anomalies, trends, or indices such as the Atlantic Multidecadal Oscillation (AMO) to understand SST variations over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time must not be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the climatology (mean over the period)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m climatology \u001b[38;5;241m=\u001b[39m sst_subset\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Compute SST anomalies\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sst_anomalies \u001b[38;5;241m=\u001b[39m sst_subset\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m climatology\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/util/deprecation_helpers.py:118\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._decorator.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({name: arg \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m zip_args})\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs[:\u001b[38;5;241m-\u001b[39mn_extra_args], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/core/dataarray.py:6874\u001b[0m, in \u001b[0;36mDataArray.groupby\u001b[0;34m(self, group, squeeze, restore_coord_dims, **groupers)\u001b[0m\n\u001b[1;32m   6867\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m   6868\u001b[0m     DataArrayGroupBy,\n\u001b[1;32m   6869\u001b[0m     _parse_group_and_groupers,\n\u001b[1;32m   6870\u001b[0m     _validate_groupby_squeeze,\n\u001b[1;32m   6871\u001b[0m )\n\u001b[1;32m   6873\u001b[0m _validate_groupby_squeeze(squeeze)\n\u001b[0;32m-> 6874\u001b[0m rgroupers \u001b[38;5;241m=\u001b[39m _parse_group_and_groupers(\u001b[38;5;28mself\u001b[39m, group, groupers)\n\u001b[1;32m   6875\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataArrayGroupBy(\u001b[38;5;28mself\u001b[39m, rgroupers, restore_coord_dims\u001b[38;5;241m=\u001b[39mrestore_coord_dims)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/core/groupby.py:366\u001b[0m, in \u001b[0;36m_parse_group_and_groupers\u001b[0;34m(obj, group, groupers)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m groupers:\n\u001b[1;32m    364\u001b[0m         grouper_mapping \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMapping[Hashable, Grouper]\u001b[39m\u001b[38;5;124m\"\u001b[39m, groupers)\n\u001b[0;32m--> 366\u001b[0m     rgroupers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    367\u001b[0m         ResolvedGrouper(grouper, group, obj)\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m group, grouper \u001b[38;5;129;01min\u001b[39;00m grouper_mapping\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rgroupers\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/core/groupby.py:367\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m groupers:\n\u001b[1;32m    364\u001b[0m         grouper_mapping \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMapping[Hashable, Grouper]\u001b[39m\u001b[38;5;124m\"\u001b[39m, groupers)\n\u001b[1;32m    366\u001b[0m     rgroupers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 367\u001b[0m         ResolvedGrouper(grouper, group, obj)\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m group, grouper \u001b[38;5;129;01min\u001b[39;00m grouper_mapping\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rgroupers\n",
      "File \u001b[0;32m<string>:6\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, grouper, group, obj)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/core/groupby.py:307\u001b[0m, in \u001b[0;36mResolvedGrouper.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;66;03m# This copy allows the BinGrouper.factorize() method\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;66;03m# to update BinGrouper.bins when provided as int, using the output\u001b[39;00m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;66;03m# of pd.cut\u001b[39;00m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;66;03m# We do not want to modify the original object, since the same grouper\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;66;03m# might be used multiple times.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper)\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m _resolve_group(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup)\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mfactorize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/core/groupby.py:432\u001b[0m, in \u001b[0;36m_resolve_group\u001b[0;34m(obj, group)\u001b[0m\n\u001b[1;32m    429\u001b[0m         newgroup \u001b[38;5;241m=\u001b[39m group_da\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newgroup\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnewgroup\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must not be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m newgroup\n",
      "\u001b[0;31mValueError\u001b[0m: time must not be empty"
     ]
    }
   ],
   "source": [
    "# Calculate the climatology (mean over the period)\n",
    "climatology = sst_subset.groupby('time').mean('time')\n",
    "\n",
    "# Compute SST anomalies\n",
    "sst_anomalies = sst_subset.groupby('time') - climatology\n",
    "\n",
    "# Calculate the AMO index (example)\n",
    "amo_index = sst_anomalies.mean(dim=['lat', 'lon'])\n",
    "\n",
    "print(climatology)\n",
    "print(sst_anomalies)\n",
    "print(amo_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Plot them to have something to see? Low Priority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">NEW</span>Incorporate the processed SST data or derived indices into your drought prediction model as predictors or covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sst_anomalies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m precipitation_data \u001b[38;5;241m=\u001b[39m full_era5[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_total_precipitation_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m#idk if it is precipitation TODO: print variable names to know\u001b[39;00m\n\u001b[1;32m      2\u001b[0m temperature_data \u001b[38;5;241m=\u001b[39m full_era5[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecipitation\u001b[39m\u001b[38;5;124m'\u001b[39m: precipitation_data,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m: temperature_data,\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msst_anomalies\u001b[39m\u001b[38;5;124m'\u001b[39m: sst_anomalies,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# TODO: Add other variables as needed\u001b[39;00m\n\u001b[1;32m      9\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sst_anomalies' is not defined"
     ]
    }
   ],
   "source": [
    "precipitation_data = full_era5['mean_total_precipitation_rate'] #idk if it is precipitation TODO: print variable names to know\n",
    "temperature_data = full_era5['temperature']\n",
    "\n",
    "model_inputs = {\n",
    "    'precipitation': precipitation_data,\n",
    "    'temperature': temperature_data,\n",
    "    'sst_anomalies': sst_anomalies,\n",
    "    # TODO: Add other variables as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DatasetAggregations.var of <xarray.Dataset> Size: 4PB\n",
      "Dimensions:                                                          (\n",
      "                                                                      time: 1323648,\n",
      "                                                                      latitude: 721,\n",
      "                                                                      longitude: 1440,\n",
      "                                                                      level: 37)\n",
      "Coordinates:\n",
      "  * latitude                                                         (latitude) float32 3kB ...\n",
      "  * level                                                            (level) int64 296B ...\n",
      "  * longitude                                                        (longitude) float32 6kB ...\n",
      "  * time                                                             (time) datetime64[ns] 11MB ...\n",
      "Data variables: (12/273)\n",
      "    100m_u_component_of_wind                                         (time, latitude, longitude) float32 5TB ...\n",
      "    100m_v_component_of_wind                                         (time, latitude, longitude) float32 5TB ...\n",
      "    10m_u_component_of_neutral_wind                                  (time, latitude, longitude) float32 5TB ...\n",
      "    10m_u_component_of_wind                                          (time, latitude, longitude) float32 5TB ...\n",
      "    10m_v_component_of_neutral_wind                                  (time, latitude, longitude) float32 5TB ...\n",
      "    10m_v_component_of_wind                                          (time, latitude, longitude) float32 5TB ...\n",
      "    ...                                                               ...\n",
      "    wave_spectral_directional_width_for_swell                        (time, latitude, longitude) float32 5TB ...\n",
      "    wave_spectral_directional_width_for_wind_waves                   (time, latitude, longitude) float32 5TB ...\n",
      "    wave_spectral_kurtosis                                           (time, latitude, longitude) float32 5TB ...\n",
      "    wave_spectral_peakedness                                         (time, latitude, longitude) float32 5TB ...\n",
      "    wave_spectral_skewness                                           (time, latitude, longitude) float32 5TB ...\n",
      "    zero_degree_level                                                (time, latitude, longitude) float32 5TB ...\n",
      "Attributes:\n",
      "    valid_time_start:  1940-01-01\n",
      "    last_updated:      2024-11-20 14:20:41.872928\n",
      "    valid_time_stop:   2024-08-31>\n",
      "<xarray.DataArray 'mean_total_precipitation_rate' (time: 1323648,\n",
      "                                                   latitude: 721,\n",
      "                                                   longitude: 1440)> Size: 5TB\n",
      "[1374264299520 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * latitude   (latitude) float32 3kB 90.0 89.75 89.5 ... -89.5 -89.75 -90.0\n",
      "  * longitude  (longitude) float32 6kB 0.0 0.25 0.5 0.75 ... 359.2 359.5 359.8\n",
      "  * time       (time) datetime64[ns] 11MB 1900-01-01 ... 2050-12-31T23:00:00\n",
      "Attributes:\n",
      "    long_name:   Mean total precipitation rate\n",
      "    short_name:  mtpr\n",
      "    units:       kg m**-2 s**-1\n",
      "10m_wind_gust_since_previous_post_processing\n",
      "convective_precipitation\n",
      "instantaneous_large_scale_surface_precipitation_fraction\n",
      "large_scale_precipitation\n",
      "large_scale_precipitation_fraction\n",
      "maximum_2m_temperature_since_previous_post_processing\n",
      "maximum_total_precipitation_rate_since_previous_post_processing\n",
      "mean_convective_precipitation_rate\n",
      "mean_large_scale_precipitation_fraction\n",
      "mean_large_scale_precipitation_rate\n",
      "mean_sea_level_pressure\n",
      "mean_total_precipitation_rate\n",
      "minimum_2m_temperature_since_previous_post_processing\n",
      "minimum_total_precipitation_rate_since_previous_post_processing\n",
      "precipitation_type\n",
      "surface_pressure\n",
      "total_precipitation\n"
     ]
    }
   ],
   "source": [
    "print(full_era5.var)\n",
    "\n",
    "print(full_era5[\"mean_total_precipitation_rate\"])\n",
    "for i in full_era5:\n",
    "    if \"pre\" in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">NEW</span> Add SST anomalies to the input variables of the NeuralGCM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9Dbth-nDjM5F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 4PB\n",
      "Dimensions:                                                          (\n",
      "                                                                      time: 1323648,\n",
      "                                                                      latitude: 721,\n",
      "                                                                      longitude: 1440,\n",
      "                                                                      level: 37)\n",
      "Coordinates:\n",
      "  * latitude                                                         (latitude) float32 3kB ...\n",
      "  * level                                                            (level) int64 296B ...\n",
      "  * longitude                                                        (longitude) float32 6kB ...\n",
      "  * time                                                             (time) datetime64[ns] 11MB ...\n",
      "Data variables: (12/273)\n",
      "    100m_u_component_of_wind                                         (time, latitude, longitude) float32 5TB ...\n",
      "    100m_v_component_of_wind                                         (time, latitude, longitude) float32 5TB ...\n",
      "    10m_u_component_of_neutral_wind                                  (time, latitude, longitude) float32 5TB ...\n",
      "    10m_u_component_of_wind                                          (time, latitude, longitude) float32 5TB ...\n",
      "    10m_v_component_of_neutral_wind                                  (time, latitude, longitude) float32 5TB ...\n",
      "    10m_v_component_of_wind                                          (time, latitude, longitude) float32 5TB ...\n",
      "    ...                                                               ...\n",
      "    wave_spectral_directional_width_for_swell                        (time, latitude, longitude) float32 5TB ...\n",
      "    wave_spectral_directional_width_for_wind_waves                   (time, latitude, longitude) float32 5TB ...\n",
      "    wave_spectral_kurtosis                                           (time, latitude, longitude) float32 5TB ...\n",
      "    wave_spectral_peakedness                                         (time, latitude, longitude) float32 5TB ...\n",
      "    wave_spectral_skewness                                           (time, latitude, longitude) float32 5TB ...\n",
      "    zero_degree_level                                                (time, latitude, longitude) float32 5TB ...\n",
      "Attributes:\n",
      "    valid_time_start:  1940-01-01\n",
      "    last_updated:      2024-11-20 14:20:41.872928\n",
      "    valid_time_stop:   2024-08-31\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"No variable named 'precipitation'. Variables on the dataset include ['100m_u_component_of_wind', '100m_v_component_of_wind', '10m_u_component_of_neutral_wind', '10m_u_component_of_wind', '10m_v_component_of_neutral_wind', ..., 'wave_spectral_directional_width_for_wind_waves', 'wave_spectral_kurtosis', 'wave_spectral_peakedness', 'wave_spectral_skewness', 'zero_degree_level']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1485\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_virtual_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'precipitation'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1588\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m                     \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\u001b[0m\u001b[0;34m\\nHint: use a list to select multiple variables, for example `ds[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]`\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1590\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1485\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_virtual_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(variables, key, dim_sizes)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0msplit_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'precipitation'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79947/1090372256.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Add SST anomalies to the input variables of the NeuralGCM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_era5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m era5_with_sst = xr.Dataset(\n\u001b[1;32m      4\u001b[0m     {\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;34m'precipitation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfull_era5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precipitation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m'temperature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfull_era5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m'humidity'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfull_era5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'specific_humidity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m'sst_anomalies'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msst_anomalies_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1586\u001b[0m                 \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\u001b[0m\u001b[0;34mNo variable named \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m!\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m. Variables on the dataset include \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mshorten_list_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m                 \u001b[0;31m# If someone attempts `ds['foo' , 'bar']` instead of `ds[['foo', 'bar']]`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1589\u001b[0m                     \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\u001b[0m\u001b[0;34m\\nHint: use a list to select multiple variables, for example `ds[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]`\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1590\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable_of_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_listed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"No variable named 'precipitation'. Variables on the dataset include ['100m_u_component_of_wind', '100m_v_component_of_wind', '10m_u_component_of_neutral_wind', '10m_u_component_of_wind', '10m_v_component_of_neutral_wind', ..., 'wave_spectral_directional_width_for_wind_waves', 'wave_spectral_kurtosis', 'wave_spectral_peakedness', 'wave_spectral_skewness', 'zero_degree_level']\""
     ]
    }
   ],
   "source": [
    "# Add SST anomalies to the input variables of the NeuralGCM model\n",
    "era5_with_sst = xr.Dataset(\n",
    "    {\n",
    "        'precipitation': full_era5['mean_total_precipitation_rate'],\n",
    "        'temperature': full_era5['temperature'],\n",
    "        'humidity': full_era5['specific_humidity'],\n",
    "        'sst_anomalies': sst_anomalies_grid,\n",
    "        # TODO: ADD remining inputs\n",
    "    },\n",
    "    coords={\n",
    "        'time': full_era5['time'],\n",
    "        'latitude': full_era5['latitude'],\n",
    "        'longitude': full_era5['longitude'],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivRFAQnt6KKF"
   },
   "source": [
    "Regrid to NeuralGCM's native resolution: <span style=\"color:red\">Rewrite it to use the sst data</span>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62wVlyCsJ-Jg"
   },
   "outputs": [],
   "source": [
    "era5_grid = spherical_harmonic.Grid(\n",
    "    latitude_nodes=full_era5.sizes['latitude'],\n",
    "    longitude_nodes=full_era5.sizes['longitude'],\n",
    "    latitude_spacing=xarray_utils.infer_latitude_spacing(full_era5.latitude),\n",
    "    longitude_offset=xarray_utils.infer_longitude_offset(full_era5.longitude),\n",
    ")\n",
    "regridder = horizontal_interpolation.ConservativeRegridder(\n",
    "    era5_grid, model.data_coords.horizontal, skipna=True\n",
    ")\n",
    "eval_era5 = xarray_utils.regrid(sliced_era5, regridder)\n",
    "eval_era5 = xarray_utils.fill_nan_with_nearest(eval_era5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">NEW</span>:Ensure that the combined dataset adheres to NeuralGCM’s expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = {\n",
    "    variable: era5_with_sst[variable].values for variable in era5_with_sst.data_vars\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrbru3K1bo81"
   },
   "source": [
    "## Make the forecast\n",
    "\n",
    "See {doc}`trained_models` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kVCC2pO8eZE0"
   },
   "outputs": [],
   "source": [
    "inner_steps = 24  # save model outputs once every 24 hours\n",
    "outer_steps = 4 * 24 // inner_steps  # total of 4 days\n",
    "timedelta = np.timedelta64(1, 'h') * inner_steps\n",
    "times = (np.arange(outer_steps) * inner_steps)  # time axis in hours\n",
    "\n",
    "# initialize model state\n",
    "# TODO: change the input with the new one\n",
    "\n",
    "\n",
    "inputs = model.inputs_from_xarray(eval_era5.isel(time=0))\n",
    "input_forcings = model.forcings_from_xarray(eval_era5.isel(time=0))\n",
    "rng_key = jax.random.key(42)  # optional for deterministic models\n",
    "initial_state = model.encode(inputs, input_forcings, rng_key)\n",
    "\n",
    "# use persistence for forcing variables (SST and sea ice cover)\n",
    "all_forcings = model.forcings_from_xarray(eval_era5.head(time=1))\n",
    "\n",
    "# make forecast\n",
    "final_state, predictions = model.unroll(\n",
    "    initial_state,\n",
    "    all_forcings,\n",
    "    steps=outer_steps,\n",
    "    timedelta=timedelta,\n",
    "    start_with_input=True,\n",
    ")\n",
    "predictions_ds = model.data_to_xarray(predictions, times=times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7lhecHtbo82"
   },
   "source": [
    "## Compare forecast to ERA5\n",
    "\n",
    "See [WeatherBench2](https://sites.research.google/weatherbench/) for more comprehensive evaluations and archived NeuralGCM forecasts.\n",
    "\n",
    "Can stay like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-GG0YrV7cMG",
    "outputId": "5438e4b5-aa35-495e-c2b5-7f43494dcb47"
   },
   "outputs": [],
   "source": [
    "# Selecting ERA5 targets from exactly the same time slice\n",
    "target_trajectory = model.inputs_from_xarray(\n",
    "    eval_era5\n",
    "    .thin(time=(inner_steps // data_inner_steps))\n",
    "    .isel(time=slice(outer_steps))\n",
    ")\n",
    "target_data_ds = model.data_to_xarray(target_trajectory, times=times)\n",
    "\n",
    "combined_ds = xarray.concat([target_data_ds, predictions_ds], 'model')\n",
    "combined_ds.coords['model'] = ['ERA5', 'NeuralGCM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 806
    },
    "id": "EUoubIO67uTW",
    "outputId": "f2acc749-a9fb-4cab-a10a-b89e2d016791"
   },
   "outputs": [],
   "source": [
    "# Visualize ERA5 vs NeuralGCM trajectories\n",
    "combined_ds.specific_humidity.sel(level=850).plot(\n",
    "    x='longitude', y='latitude', row='time', col='model', robust=True, aspect=2, size=2\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96H8CLDo3Rzx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tkGJv8VEgFa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
